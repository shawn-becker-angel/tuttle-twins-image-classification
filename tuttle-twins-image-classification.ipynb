{"cells":[{"cell_type":"markdown","metadata":{},"source":[" **Note:** Igonre or comment jovian lines if you are running this notebook."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-05-15T14:59:54.633875Z","iopub.status.busy":"2022-05-15T14:59:54.633166Z","iopub.status.idle":"2022-05-15T14:59:58.715978Z","shell.execute_reply":"2022-05-15T14:59:58.714806Z","shell.execute_reply.started":"2022-05-15T14:59:54.63383Z"},"trusted":true},"outputs":[],"source":["# The original version of this notebook was downloaded from: \n","# https://www.kaggle.com/code/osamaeldemerdash/image-classification-cnn and\n","# https://www.kaggle.com/code/pranjalsoni17/natural-scene-classification\n","\n","#project name\n","project_name = 'tuttle-twins-image-classification'"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2022-05-15T15:00:32.202931Z","iopub.status.busy":"2022-05-15T15:00:32.202439Z","iopub.status.idle":"2022-05-15T15:00:33.630943Z","shell.execute_reply":"2022-05-15T15:00:33.629497Z","shell.execute_reply.started":"2022-05-15T15:00:32.202882Z"},"trusted":true},"outputs":[],"source":["!python3 -m pip install --upgrade pip\n","\n","%pip install pandas\n","%pip install numpy\n","%pip install torch\n","%pip install torchvision\n","%pip install matplotlib\n","%pip install opencv-python\n","print(\"done\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:16.578152Z","iopub.status.busy":"2022-05-15T11:28:16.577587Z","iopub.status.idle":"2022-05-15T11:28:18.072361Z","shell.execute_reply":"2022-05-15T11:28:18.071127Z","shell.execute_reply.started":"2022-05-15T11:28:16.57809Z"},"trusted":true},"outputs":[],"source":["#import necessory libraries\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import torch\n","import torchvision\n","import matplotlib.pyplot as plt\n","import cv2\n","import datetime\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms\n","from torchvision.utils import make_grid\n","from torch.utils.data.dataloader import DataLoader\n","from torch.utils.data import random_split\n","%matplotlib inline\n","print(\"done\")"]},{"cell_type":"markdown","metadata":{},"source":["> # **Exploring the Dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# e.g. TT_S01_E02_FRM-00-19-05-09.jpg\n","SOURCE_IMAGES_DIR = \"../src-images/\"\n","\n","# pred_data.csv   test_data.csv   train_data.csv\n","CSV_DATA_DIR = \"../csv-data/\"\n","\n","STAGES = [\"train\", \"test\", \"pred\"]"]},{"cell_type":"markdown","metadata":{},"source":["## Pre-process csv data files"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def pre_process_csv_stage_data(stage):\n","    '''\n","    read the csv_data file for the given stage\n","    and return its X_images and y_labels\n","    '''\n","    \n","    assert stage in STAGES\n","    \n","    csv_data_file = f\"{CSV_DATA_DIR}{stage}_data.csv\"\n","    print(f\"pre-processing: {csv_data_file}\")\n","    \n","    df = pd.read_csv(csv_data_file, header=None, names=['file_name', 'label'])\n","    X_file_names = df[\"file_name\"].to_list()\n","    y_labels = df[\"label\"].to_list()\n","    \n","    print(f\"X_{stage}_file_names: {len(X_file_names)}\")\n","    print(f\"y_{stage}labels: {len(y_labels)}\")\n","\n","    # review X image sizes\n","    X_size = []\n","    for i in range(len(X_file_names)):\n","        image = plt.imread(SOURCE_IMAGES_DIR + X_file_names[i])\n","        X_size.append(image.shape)\n","    pd.Series(X_size).value_counts()\n","    \n","    # Read and resize X_images\n","    size = 100\n","    X_images = []\n","    for i in range(len(X_file_names)):\n","        im_cv = cv2.imread(SOURCE_IMAGES_DIR + X_file_names[i])\n","        im_rgb = cv2.cvtColor(im_cv, cv2.COLOR_BGR2RGB)\n","        image_array = cv2.resize(im_rgb, (size,size), interpolation=cv2.INTER_AREA)\n","        X_images.append(list(image_array))\n","\n","    print(f\"X_{stage}_images: {len(X_images)} images resized to {size}x{size} pixels\")\n","    \n","    return (X_images, y_labels)\n","\n","\n","def create_random_seed(num_digits=3):\n","    '''\n","    Use the last num_digits [1..6]chars of the current utc time in \n","    ISO8601 format to create a random num_digit number\n","    '''\n","    num_digits = min(max(1,num_digits),6)\n","    iso_str = datetime.datetime.utcnow().isoformat()\n","    return int(iso_str[-num_digits:])\n","\n","\n","def display_X_stage_images(stage, X_images, y_labels):\n","    '''\n","    Display a random selection of 36 X_images and their y_labels\n","    '''\n","    np.random.seed(create_random_seed())\n","    num_images = min(36, len(X_images))\n","    print(f\"Displaying a random selection of {num_images} X_{stage}_images and their y_{stage}_labels\")\n","    \n","    plt.figure(figsize=(20,20))\n","    for n , i in enumerate(list(np.random.randint(0,len(X_images),num_images))) : \n","        plt.subplot(6,6,n+1)\n","        plt.imshow(X_images[i])   \n","        plt.axis('off')\n","        plt.title(f\"{y_labels[i]} @ {i}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Pre-process and display the train data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["(X_train, y_train) = pre_process_csv_stage_data(stage=\"train\")\n","display_X_stage_images(stage=\"train\", X_images=X_train, y_labels=y_train)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Pre-process and display the test data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["(X_test, y_test) = pre_process_csv_stage_data(stage=\"test\")\n","display_X_stage_images(stage=\"test\", X_images=X_test, y_labels=y_test)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:18.38636Z","iopub.status.busy":"2022-05-15T11:28:18.386032Z","iopub.status.idle":"2022-05-15T11:28:31.882703Z","shell.execute_reply":"2022-05-15T11:28:31.881529Z","shell.execute_reply.started":"2022-05-15T11:28:18.386328Z"},"trusted":true},"source":["## Pre-process and display the pred data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:31.884376Z","iopub.status.busy":"2022-05-15T11:28:31.884093Z","iopub.status.idle":"2022-05-15T11:28:31.960478Z","shell.execute_reply":"2022-05-15T11:28:31.95934Z","shell.execute_reply.started":"2022-05-15T11:28:31.884345Z"},"trusted":true},"outputs":[],"source":["(X_pred, y_pred) = pre_process_csv_stage_data(stage=\"pred\")\n","display_X_stage_images(stage=\"pred\", X_images=X_pred, y_labels=y_pred)"]},{"cell_type":"markdown","metadata":{},"source":["> # Training and Validation Datasets : "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:32.646632Z","iopub.status.busy":"2022-05-15T11:28:32.646139Z","iopub.status.idle":"2022-05-15T11:28:32.656188Z","shell.execute_reply":"2022-05-15T11:28:32.655284Z","shell.execute_reply.started":"2022-05-15T11:28:32.646588Z"},"trusted":true},"outputs":[],"source":["random_seed = 2021\n","torch.manual_seed(random_seed)"]},{"cell_type":"markdown","metadata":{},"source":["> # Load the datasets into batches:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:32.685347Z","iopub.status.busy":"2022-05-15T11:28:32.684818Z","iopub.status.idle":"2022-05-15T11:28:32.697062Z","shell.execute_reply":"2022-05-15T11:28:32.696044Z","shell.execute_reply.started":"2022-05-15T11:28:32.685309Z"},"trusted":true},"outputs":[],"source":["# Create train and test datasets\n","train_ds = tuple(zip(X_train,y_train))\n","test_ds = tuple(zip(X_test,y_test))\n","\n","batch_size = 100\n","\n","# load the datasets into batches\n","train_dl = DataLoader(\n","    train_ds, batch_size=batch_size, shuffle=False, \n","    num_workers=0, collate_fn=None, pin_memory=False)\n","\n","test_dl = DataLoader(\n","    test_ds, batch_size=batch_size*2, shuffle=False, \n","    num_workers=0, collate_fn=None, pin_memory=False)\n","\n","print(\"train_dl in batches\")\n","for batch_idx, samples in enumerate(train_dl):\n","      print(\"***\", batch_idx, samples)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:32.698887Z","iopub.status.busy":"2022-05-15T11:28:32.698548Z","iopub.status.idle":"2022-05-15T11:28:32.7081Z","shell.execute_reply":"2022-05-15T11:28:32.707152Z","shell.execute_reply.started":"2022-05-15T11:28:32.698853Z"},"trusted":true},"outputs":[],"source":["from torchvision.utils import make_grid\n","\n","def show_batch(dl):\n","    for images, labels in dl:\n","        fig,ax = plt.subplots(figsize = (16,12))\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        ax.imshow(make_grid(images,nrow=16).permute(1,2,0))\n","        break"]},{"cell_type":"markdown","metadata":{},"source":["> # **Grid Of Train Data Images :**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:32.71002Z","iopub.status.busy":"2022-05-15T11:28:32.709623Z","iopub.status.idle":"2022-05-15T11:28:35.586299Z","shell.execute_reply":"2022-05-15T11:28:35.584675Z","shell.execute_reply.started":"2022-05-15T11:28:32.709983Z"},"trusted":true},"outputs":[],"source":["# show a 16x8 grid ofimages\n","show_batch(train_dl)"]},{"cell_type":"markdown","metadata":{},"source":["> # Base Model for Image Classification:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:35.589076Z","iopub.status.busy":"2022-05-15T11:28:35.588567Z","iopub.status.idle":"2022-05-15T11:28:35.609517Z","shell.execute_reply":"2022-05-15T11:28:35.608037Z","shell.execute_reply.started":"2022-05-15T11:28:35.589023Z"},"trusted":true},"outputs":[],"source":["class ImageClassificationBase(nn.Module):\n","    \n","    def training_step(self, batch):\n","        images, labels = batch \n","        out = self(images)                  # Generate predictions\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","    \n","    def validation_step(self, batch):\n","        images, labels = batch \n","        out = self(images)                    # Generate predictions\n","        loss = F.cross_entropy(out, labels)   # Calculate loss\n","        acc = accuracy(out, labels)           # Calculate accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc}\n","        \n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","    \n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n","        \n","def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"]},{"cell_type":"markdown","metadata":{},"source":["# Netural Scene Classfication Model:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:35.611253Z","iopub.status.busy":"2022-05-15T11:28:35.610796Z","iopub.status.idle":"2022-05-15T11:28:35.626472Z","shell.execute_reply":"2022-05-15T11:28:35.625552Z","shell.execute_reply.started":"2022-05-15T11:28:35.611216Z"},"trusted":true},"outputs":[],"source":["class NaturalSceneClassification(ImageClassificationBase):\n","    \n","    def __init__(self):\n","        \n","        super().__init__()\n","        self.network = nn.Sequential(\n","            \n","            nn.Conv2d(3, 32, kernel_size = 3, padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(32,64, kernel_size = 3, stride = 1, padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2),\n","        \n","            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(128 ,128, kernel_size = 3, stride = 1, padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2),\n","            \n","            nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(256,256, kernel_size = 3, stride = 1, padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2,2),\n","            \n","            nn.Flatten(),\n","            nn.Linear(82944,1024),\n","            nn.ReLU(),\n","            nn.Linear(1024, 512),\n","            nn.ReLU(),\n","            nn.Linear(512,6)\n","        )\n","    \n","    def forward(self, xb):\n","        return self.network(xb)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:35.62807Z","iopub.status.busy":"2022-05-15T11:28:35.627654Z","iopub.status.idle":"2022-05-15T11:28:36.445817Z","shell.execute_reply":"2022-05-15T11:28:36.444543Z","shell.execute_reply.started":"2022-05-15T11:28:35.62803Z"},"trusted":true},"outputs":[],"source":["model = NaturalSceneClassification()\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:36.448471Z","iopub.status.busy":"2022-05-15T11:28:36.447983Z","iopub.status.idle":"2022-05-15T11:28:50.582271Z","shell.execute_reply":"2022-05-15T11:28:50.581126Z","shell.execute_reply.started":"2022-05-15T11:28:36.448421Z"},"trusted":true},"outputs":[],"source":["for images, labels in train_dl:\n","    print('images.shape:', images.shape)\n","    out = model(images)\n","    print('out.shape:', out.shape)\n","    print('out[0]:', out[0])\n","    break"]},{"cell_type":"markdown","metadata":{},"source":["Helper Function or classes to Load Data into GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:50.584704Z","iopub.status.busy":"2022-05-15T11:28:50.584118Z","iopub.status.idle":"2022-05-15T11:28:50.599699Z","shell.execute_reply":"2022-05-15T11:28:50.598438Z","shell.execute_reply.started":"2022-05-15T11:28:50.584656Z"},"trusted":true},"outputs":[],"source":["def get_default_device():\n","    \"\"\" Set Device to GPU or CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","    \n","\n","def to_device(data, device):\n","    \"Move data to the device\"\n","    if isinstance(data,(list,tuple)):\n","        return [to_device(x,device) for x in data]\n","    return data.to(device,non_blocking = True)\n","\n","class DeviceDataLoader():\n","    \"\"\" Wrap a dataloader to move data to a device \"\"\"\n","    \n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","    \n","    def __iter__(self):\n","        \"\"\" Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl:\n","            yield to_device(b,self.device)\n","            \n","    def __len__(self):\n","        \"\"\" Number of batches \"\"\"\n","        return len(self.dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:50.602259Z","iopub.status.busy":"2022-05-15T11:28:50.601524Z","iopub.status.idle":"2022-05-15T11:28:50.621706Z","shell.execute_reply":"2022-05-15T11:28:50.620662Z","shell.execute_reply.started":"2022-05-15T11:28:50.60221Z"},"trusted":true},"outputs":[],"source":["device = get_default_device()\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:50.624224Z","iopub.status.busy":"2022-05-15T11:28:50.623417Z","iopub.status.idle":"2022-05-15T11:28:50.638976Z","shell.execute_reply":"2022-05-15T11:28:50.637798Z","shell.execute_reply.started":"2022-05-15T11:28:50.624165Z"},"trusted":true},"outputs":[],"source":["# load the train and validation data into the device\n","train_dl = DeviceDataLoader(train_dl, device)\n","val_dl = DeviceDataLoader(val_dl, device)\n","to_device(model, device)"]},{"cell_type":"markdown","metadata":{},"source":["> # **Model Fitting**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:50.641577Z","iopub.status.busy":"2022-05-15T11:28:50.640816Z","iopub.status.idle":"2022-05-15T11:28:50.655246Z","shell.execute_reply":"2022-05-15T11:28:50.654023Z","shell.execute_reply.started":"2022-05-15T11:28:50.641525Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def evaluate(model, val_loader):\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)\n","\n","def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):\n","    \n","    history = []\n","    optimizer = opt_func(model.parameters(),lr)\n","    for epoch in range(epochs):\n","        \n","        model.train()\n","        train_losses = []\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            train_losses.append(loss)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            \n","        result = evaluate(model, val_loader)\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        model.epoch_end(epoch, result)\n","        history.append(result)\n","    \n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:50.663723Z","iopub.status.busy":"2022-05-15T11:28:50.66275Z","iopub.status.idle":"2022-05-15T11:28:51.472451Z","shell.execute_reply":"2022-05-15T11:28:51.471301Z","shell.execute_reply.started":"2022-05-15T11:28:50.663665Z"},"trusted":true},"outputs":[],"source":["#load the model to the device\n","model = to_device(NaturalSceneClassification(),device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:28:51.474617Z","iopub.status.busy":"2022-05-15T11:28:51.474076Z","iopub.status.idle":"2022-05-15T11:31:47.993531Z","shell.execute_reply":"2022-05-15T11:31:47.992369Z","shell.execute_reply.started":"2022-05-15T11:28:51.474578Z"},"trusted":true},"outputs":[],"source":["#initial evaluation of the model\n","evaluate(model,val_dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:31:47.995685Z","iopub.status.busy":"2022-05-15T11:31:47.995314Z","iopub.status.idle":"2022-05-15T11:31:48.000538Z","shell.execute_reply":"2022-05-15T11:31:47.999635Z","shell.execute_reply.started":"2022-05-15T11:31:47.995641Z"},"trusted":true},"outputs":[],"source":["#set the no. of epochs, optimizer funtion and learning rate\n","num_epochs = 30\n","opt_func = torch.optim.Adam\n","lr = 0.001"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-15T11:31:48.002705Z","iopub.status.busy":"2022-05-15T11:31:48.002182Z","iopub.status.idle":"2022-05-15T11:46:11.265813Z","shell.execute_reply":"2022-05-15T11:46:11.263234Z","shell.execute_reply.started":"2022-05-15T11:31:48.002667Z"},"trusted":true},"outputs":[],"source":["#fitting the model on training data and record the result after each epoch\n","history = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)"]},{"cell_type":"markdown","metadata":{},"source":["> # Graphs for Model Accuracy and Losses :"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:46:11.268032Z","iopub.status.idle":"2022-05-15T11:46:11.268836Z"},"trusted":true},"outputs":[],"source":["def plot_accuracies(history):\n","    \"\"\" Plot the history of accuracies\"\"\"\n","    accuracies = [x['val_acc'] for x in history]\n","    plt.plot(accuracies, '-x')\n","    plt.xlabel('epoch')\n","    plt.ylabel('accuracy')\n","    plt.title('Accuracy vs. No. of epochs');\n","    \n","\n","plot_accuracies(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:46:11.270823Z","iopub.status.idle":"2022-05-15T11:46:11.271855Z"},"trusted":true},"outputs":[],"source":["def plot_losses(history):\n","    \"\"\" Plot the losses in each epoch\"\"\"\n","    train_losses = [x.get('train_loss') for x in history]\n","    val_losses = [x['val_loss'] for x in history]\n","    plt.plot(train_losses, '-bx')\n","    plt.plot(val_losses, '-rx')\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss')\n","    plt.legend(['Training', 'Validation'])\n","    plt.title('Loss vs. No. of epochs');\n","\n","plot_losses(history)"]},{"cell_type":"markdown","metadata":{},"source":["> # Evaluate Test Data :"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:46:11.273726Z","iopub.status.idle":"2022-05-15T11:46:11.27482Z"},"trusted":true},"outputs":[],"source":["# Apply the model on test dataset and Get the results\n","test_loader = DeviceDataLoader(DataLoader(test_dataset, batch_size*2), device)\n","result = evaluate(model, test_loader)\n","result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:46:11.276627Z","iopub.status.idle":"2022-05-15T11:46:11.277687Z"},"trusted":true},"outputs":[],"source":["#save the model\n","torch.save(model.state_dict(), 'natural-scene-classification.pth')"]},{"cell_type":"markdown","metadata":{},"source":["> ## Predicting for invisual images:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:46:11.279511Z","iopub.status.idle":"2022-05-15T11:46:11.280585Z"},"trusted":true},"outputs":[],"source":["def predict_img_class(img,model):\n","    \"\"\" Predict the class of image and Return Predicted Class\"\"\"\n","    img = to_device(img.unsqueeze(0), device)\n","    prediction =  model(img)\n","    _, preds = torch.max(prediction, dim = 1)\n","    return dataset.classes[preds[0].item()]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:46:11.282352Z","iopub.status.idle":"2022-05-15T11:46:11.283399Z"},"trusted":true},"outputs":[],"source":["from PIL import Image\n","\n","#open image file\n","img = Image.open(\"../input/intel-image-classification/seg_pred/seg_pred/10004.jpg\")\n","\n","#convert image to tensor\n","img = transforms.ToTensor()(img)\n","\n","#print image\n","plt.imshow(img.permute(1,2,0))\n","\n","#prdict image label\n","print(f\"Predicted Class : {predict_img_class(img,model)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:46:11.285162Z","iopub.status.idle":"2022-05-15T11:46:11.286203Z"},"trusted":true},"outputs":[],"source":["#open image file\n","img = Image.open(\"../input/intel-image-classification/seg_pred/seg_pred/10100.jpg\")\n","\n","#convert image to tensor\n","img = transforms.ToTensor()(img)\n","\n","#print image\n","plt.imshow(img.permute(1,2,0))\n","\n","#prdict image label\n","print(f\"Predicted Class : {predict_img_class(img,model)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:46:11.287951Z","iopub.status.idle":"2022-05-15T11:46:11.289008Z"},"trusted":true},"outputs":[],"source":["#open image file\n","img = Image.open(\"../input/intel-image-classification/seg_pred/seg_pred/10241.jpg\")\n","\n","#convert image to tensor\n","img = transforms.ToTensor()(img)\n","\n","#print image\n","plt.imshow(img.permute(1,2,0))\n","\n","#prdict image label\n","print(f\"Predicted Class : {predict_img_class(img,model)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-05-15T11:46:11.29074Z","iopub.status.idle":"2022-05-15T11:46:11.291832Z"},"trusted":true},"outputs":[],"source":["img.shape"]},{"cell_type":"markdown","metadata":{},"source":["<!-- Save the parmeters to jovian plateform -->"]}],"metadata":{"interpreter":{"hash":"366fffa44e6dbdb59f6ef3b9069558a28a03d278d01afa04fb6415cbc143bb28"},"kernelspec":{"display_name":"venv","language":"python","name":"venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
